\chapter{序論}

\section{研究背景}
今日の一般家庭のインターネット接続環境が, ギガビット級の速度に達しようとしている中, 多様な端末がインターネットに接続できるようになり,
大量かつ多種多様なデータの取得が可能となった.
特にトラフィックデータ量の増加傾向は顕著で, 18$\sim$24ヶ月単位で総データ容量が2倍になるという予測がされている~\cite{IBM_rep}.
またFacebookでは, 300ペタバイト以上のデータ量を保有しており, 1日あたりに1ペタバイトのデータを解析している~\cite{presto}.
このように近年では, ビッグデータの活用が着目され, 例えばウェブ検索エンジン, SNS(Social Networking
Service)などのデータセンターを用いたクラウド型サービスにおいて, リアルタイムに近いレスポンスを返すような場面で使われ始めている.
そのようなクラウドサービスには近年, より高いユーザーエクスペリエンスが要求されており,
Amazonでは100[ms]の遅延により売り上げが1\%下がる, といった報告~\cite{amazon}があるように,
例えばeコマースサイトでの商品購入や,
インターネット広告のコンバージョンのようなユーザの意思決定へのレスポンス遅延の影響は深刻な問題である~\cite{customer_impact}.
そのため, 大規模データをより高速に処理することが求められており, データセンターではサーバ運用台数が増加の一途を辿っている.
そうした中で, 可用性, 計算性能, 低コストの三つの要件がデータセンターの抱える課題となっている~\cite{requirement}.
特に計算性能について, 大量の計算機資源から最大限の性能を引き出すためには,
従来の仕組みではデータセンター内トラフィックに対して一部の資源にトラフィックが集中する問題に対応できないため,
計算機資源を有効活用するための研究が盛んに行われている\cite{mapreduce, fattree,
dctcp, improving, detail, p_fab, synchro}.
そのようなスケーラビリティ拡大には, ネットワークトポロジー, アプリケーション, プロトコルに対する三つのアプローチがある.

ネットワークトポロジーを改良するアプローチでは, 近年データセンター内の通信帯域が1Gbpsから10Gbps, 40Gbps,
100Gbpsへと拡大していく中で, 従来の単純な二分木階層構造では,
データセンター内で発生するトラフィックに対して通信帯域を最大限割り当てることができない~\cite{fattree}.
そのため,
近年ではデータセンター内のトラフィックに対してスイッチを二段, 三段と少ない段数で構成し,
エンドノードから接続されるEdgeスイッチとそれらを集約するためのAggregationスイッチをより多く用いて接続することで, 
垂直方向には低く, 鉛直方向には大きく広がるトポロジーを提案している. 
これによって, データセンター内のトラフィックに対して通信帯域を有効利用することができる. 
また, データセンター内の通信においては, ノード間の通信経路が複数設けられており, 仮に一つの通信経路が切断されてしまったとしても,
残りの経路を用いて通信することができる, 可用性を持ち合わせたマルチパス環境を実現している~\cite{fattree}.
さらに, 近年のデータセンタートポロジーの動向として, 通信機器のコモディティ化があり, 特殊なデバイスや高価な機器を用いずに,
安価で汎用性のある機器を複数利用することで, 同等の性能を出そうと, 低コスト化を目指している. 

大量データの処理速度を改良するアプローチでは, データセンターの抱える巨大なデータの有効活用のために, 並列分散処理技術を用いることが一般的である. 
並列分散処理技術によって, 一つの処理を複数のサーバで同時並列で処理をすることで,
高スループットなデータ処理を実現しており, 大量の計算機資源から最大限の性能を引き出している. 
こうした並列分散処理技術ではpartition-aggregate計算モデルによって, 処理を細分化し, 各サーバに処理を割り当て, 結果を集約していき,
処理を完結させていく. 
こうした並列分散処理システムのアーキテクチャ上, 細分化された処理をそれぞれの処理サーバに割り当てる際, また計算結果を集約していく際に, 
サイズの小さいデータの通信が大量に発生し, データセンターネットワークの性能改善のボトルネックとなっている. 
MapReduce~\cite{mapreduce}等の並列分散処理フレームワークは,
これに従っており, 今日の大規模クラウドサービスにおいて必要不可欠である.

プロトコルを改良するアプローチでは, 
従来のTCPを拡張したMultipath TCP
(MPTCP)~\cite{mptcp}をデータセンターネットワークに用いる提案がされている~\cite{fattree}.
MPTCPを用いることにより, OSの制御によって複数のNIC(Network Interface Card), 複数の経路を同時に利用し,
スループットを向上させることが期待されている.
また, 近年のマルチパス環境を持つトポロジーにおいて, 一つの通信経路が切断された中でも,
一つのデータ通信の中で, 他の経路を使って途切れることなくデータ転送できる, 耐障害性を実現している. 
MPTCPでは, 従来のTCPと同様に, 3ウェイ・ハンドシェイク互いのコネクションを確立させ, その直後に互いの持っている他のIPアドレスを交換する. 
その後, サブフローを形成し, 複数の経路での通信をしていく. 
このためMPTCPの実装上, 比較的サイズの小さい通信では, サブフローを形成する前に通信が完了し, 結果的に一つの経路でのみ通信が行われることとなる. 

クラウド型サービスを実現するデータセンターネットワークにおいて,
並列分散処理アプリケーションによって大量に生成されたショートフロー通信が改善の課題となっている. \cite{improving}
実際, データセンター内でのトラフィックの内, 約80\%がショートフローであり, 並列分散処理の構造上,
ショートフロー通信時間が大規模計算処理高速化のための極めて重要な要素となっている. 

しかし, 既存のTCPを用いたクラウド環境では, このショートフロー通信の一部が大きく遅延する問題が報告されており,
既存のデータセンターネットワークを改善する上で, ショートフローの遅延の問題は深刻であると言える\cite{improving, rtt}.


\section{研究目的}
データセンターにおけるマルチパス環境でのショートフロー遅延の問題は並列分散処理性能の面で深刻な問題であり,
本研究は, 低レイテンシなネットワークによるコンスタントに性能の出せるデータセンターの実現を目指す.
そのために二つの手法を提案する. 

一つ目は, 異なる通信目的によって経路を切り替えるための通信レーンを複数設けるデータセンターモデルを提案する. 
これによって, 通信開始付近の経路については, 輻輳のない良好な通信環境である, ショートフローレーンで通信することができ,
その通信がショートフローであるならば, 遅延なく通信を終えることができる. 
比較的長い時間ショートフローレーンを占有するならば, ショートフローレーンからロングフローレーンへと通信経路を切り替え, 通信を行う. 
このモデルによって, ショートフローの遅延を抑え, ロングフローはショートフロー通信に干渉しない制御が実現できる. 

二つ目は, MPTCPを応用した通信経路切り替え手法を提案する. 
この手法によって, データサイズの小さいフローについては, ショートフローレーンを用いて遅延なく通信を完了させる. 
また各経路について, 通信状況を監視し, それぞれコストを計算することで, 通信経路を切り替える制御を実現する. 
この手法によって, 一つの経路に偏ることなく, それぞれの経路に均一に通信が割り振ることができる. 
さらにこの手法の実装には, Multipath TCPを応用して実現することで, OSベースで既存のアプリケーションに対して変更なく,
現実世界へ適用することが可能になる. 

\section{本研究の貢献}
本研究では, 提案手法を設計する指針となった取り組みについて, 二つの成果がある. 

一つは, MPTCPとTCPが互いに混在するような通信環境において, MPTCPがTCP通信に対して性能劣化を引き起こすという点である. 
主に通信経路の輻輳により, 通信開始時にパケットロスが生じることで遅延が生じることが分かり, 輻輳している経路を避け, 適切な経路を選択するためには,
コネクションを接続する時点で行う必要があることを示した. 

二つ目は, 実際の並列分散処理アプリケーションがどのようなトラフィックを生成するのか解析を行った. 
この解析によって, 並列分散処理アプリケーション特有のトラフィックを明確にし, 
それによって汎用的なネットワーク機器を用いたデータセンターにおけるショートフロー遅延が生じる背景について, ボトルネックとなりうるネットワーク環境を検討し,
その原因を示した.

本研究で提案したネットワークモデルと通信経路切り替え手法は, サイズ小さいショートフロー通信における遅延を抑えることができた. 
本研究の成果により, 通信時間の長いサイズの大きいフローについては, MPTCPにより高スループット化を実現した. 
また, 既存のデータセンター内通信では, サイズの大きいフローの影響を受け, 通信時間の短いショートフローが遅延してしまっていたのに対し, 本店案手法によって,
特に遅延していた, 下位10\%のフローに対して, 通信時間の短縮かを実現できた. 
さらに, 本研究の提案手法では, MPTCPを応用することによるOSベースの手法であるため,
OSを書き換えるだけで利用することができるという実現可能性が高い手法としての利点がある. 

\section{本研究の構成}
本論文の構成は以下の通りである. 
第\ref{chapter:related_work}章では, 低レイテンシなデータセンターネットワークに関する研究について, アプローチする場所ごとに述べ,
データセンターネットワークが抱えている要求案件と 既存研究手法の課題を議論する. 
第\ref{chapter:datacenter_network}章では, データセンターが構成する技術要素と抱えている技術的課題を述べ,
提案手法の位置付けを示す. 
第\ref{chapter:motivated_work}章では, 既存技術の抱える課題やこれまで報告された問題点を, 再現実験により改めて見直すことにより,
提案手法の設計する上での指針を示す. 
第\ref{chapter:proposal}章では,
複数のレーンを用いたデータセンターモデルとMPTCPを応用した通信経路切り替えアルゴリズムを併用した本研究のショートフロー改善手法を提案し, 既存研究との差異を明確にすることで, 本研究の位置付けを明らかにする. 
第\ref{chapter:evaluation}章では, 実際のデータセンターネットワークを想定したトラフィックに対して, 提案手法と既存手法を比較,
また提案手法の性能評価実験の方法と結果について述べる. 
第\ref{chapter:consideration}章では, 実験の考察と実験結果をもとにした提案手法の応用に関する考察を述べる. 
最後に, 第\ref{chapter:conclusion}章で, まとめと今後の課題について述べる. 
